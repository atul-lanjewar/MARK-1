{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f6df4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['seaborn-dark-palette','dark_background'])\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee78a5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Price</th>\n",
       "      <th>No of Bedrooms</th>\n",
       "      <th>No of Bathrooms</th>\n",
       "      <th>Flat Area (in Sqft)</th>\n",
       "      <th>Lot Area (in Sqft)</th>\n",
       "      <th>No of Floors</th>\n",
       "      <th>No of Times Visited</th>\n",
       "      <th>Overall Grade</th>\n",
       "      <th>Area of the House from Basement (in Sqft)</th>\n",
       "      <th>Basement Area (in Sqft)</th>\n",
       "      <th>...</th>\n",
       "      <th>Waterfront_View_Yes</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_1</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_2</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_3</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_4</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_5</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_6</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_7</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_8</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>5650.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>7242.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>910</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>8080.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sale_Price  No of Bedrooms  No of Bathrooms  Flat Area (in Sqft)  \\\n",
       "0    221900.0               3             1.00               1180.0   \n",
       "1    538000.0               3             2.25               2570.0   \n",
       "2    180000.0               2             1.00                770.0   \n",
       "3    604000.0               4             3.00               1960.0   \n",
       "4    510000.0               3             2.00               1680.0   \n",
       "\n",
       "   Lot Area (in Sqft)  No of Floors  No of Times Visited  Overall Grade  \\\n",
       "0              5650.0           1.0                    0              7   \n",
       "1              7242.0           2.0                    0              7   \n",
       "2             10000.0           1.0                    0              6   \n",
       "3              5000.0           1.0                    0              7   \n",
       "4              8080.0           1.0                    0              8   \n",
       "\n",
       "   Area of the House from Basement (in Sqft)  Basement Area (in Sqft)  ...  \\\n",
       "0                                     1180.0                        0  ...   \n",
       "1                                     2170.0                      400  ...   \n",
       "2                                      770.0                        0  ...   \n",
       "3                                     1050.0                      910  ...   \n",
       "4                                     1680.0                        0  ...   \n",
       "\n",
       "   Waterfront_View_Yes  Zipcode_Group_Zipcode_Group_1  \\\n",
       "0                    0                              0   \n",
       "1                    0                              0   \n",
       "2                    0                              0   \n",
       "3                    0                              0   \n",
       "4                    0                              0   \n",
       "\n",
       "   Zipcode_Group_Zipcode_Group_2  Zipcode_Group_Zipcode_Group_3  \\\n",
       "0                              0                              0   \n",
       "1                              1                              0   \n",
       "2                              1                              0   \n",
       "3                              0                              1   \n",
       "4                              0                              0   \n",
       "\n",
       "   Zipcode_Group_Zipcode_Group_4  Zipcode_Group_Zipcode_Group_5  \\\n",
       "0                              0                              0   \n",
       "1                              0                              0   \n",
       "2                              0                              0   \n",
       "3                              0                              0   \n",
       "4                              1                              0   \n",
       "\n",
       "   Zipcode_Group_Zipcode_Group_6  Zipcode_Group_Zipcode_Group_7  \\\n",
       "0                              0                              0   \n",
       "1                              0                              0   \n",
       "2                              0                              0   \n",
       "3                              0                              0   \n",
       "4                              0                              0   \n",
       "\n",
       "   Zipcode_Group_Zipcode_Group_8  Zipcode_Group_Zipcode_Group_9  \n",
       "0                              0                              0  \n",
       "1                              0                              0  \n",
       "2                              0                              0  \n",
       "3                              0                              0  \n",
       "4                              0                              0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Transformed_Housing_Data2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c3c0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df3178f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No of Bedrooms</th>\n",
       "      <th>No of Bathrooms</th>\n",
       "      <th>Flat Area (in Sqft)</th>\n",
       "      <th>Lot Area (in Sqft)</th>\n",
       "      <th>No of Floors</th>\n",
       "      <th>No of Times Visited</th>\n",
       "      <th>Overall Grade</th>\n",
       "      <th>Area of the House from Basement (in Sqft)</th>\n",
       "      <th>Basement Area (in Sqft)</th>\n",
       "      <th>Age of House (in Years)</th>\n",
       "      <th>...</th>\n",
       "      <th>Waterfront_View_Yes</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_1</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_2</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_3</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_4</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_5</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_6</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_7</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_8</th>\n",
       "      <th>Zipcode_Group_Zipcode_Group_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.398724</td>\n",
       "      <td>-1.447526</td>\n",
       "      <td>-0.979905</td>\n",
       "      <td>-0.228291</td>\n",
       "      <td>-0.915389</td>\n",
       "      <td>-0.30579</td>\n",
       "      <td>-0.563993</td>\n",
       "      <td>-0.734722</td>\n",
       "      <td>-0.658697</td>\n",
       "      <td>0.544734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087181</td>\n",
       "      <td>-0.350481</td>\n",
       "      <td>-0.482158</td>\n",
       "      <td>-0.419600</td>\n",
       "      <td>-0.479094</td>\n",
       "      <td>-0.214086</td>\n",
       "      <td>-0.287712</td>\n",
       "      <td>-0.112274</td>\n",
       "      <td>-0.16885</td>\n",
       "      <td>-0.048158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.398724</td>\n",
       "      <td>0.175684</td>\n",
       "      <td>0.533718</td>\n",
       "      <td>-0.189858</td>\n",
       "      <td>0.936817</td>\n",
       "      <td>-0.30579</td>\n",
       "      <td>-0.563993</td>\n",
       "      <td>0.460990</td>\n",
       "      <td>0.245134</td>\n",
       "      <td>0.680915</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087181</td>\n",
       "      <td>-0.350481</td>\n",
       "      <td>2.074011</td>\n",
       "      <td>-0.419600</td>\n",
       "      <td>-0.479094</td>\n",
       "      <td>-0.214086</td>\n",
       "      <td>-0.287712</td>\n",
       "      <td>-0.112274</td>\n",
       "      <td>-0.16885</td>\n",
       "      <td>-0.048158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.474115</td>\n",
       "      <td>-1.447526</td>\n",
       "      <td>-1.426369</td>\n",
       "      <td>-0.123276</td>\n",
       "      <td>-0.915389</td>\n",
       "      <td>-0.30579</td>\n",
       "      <td>-1.468566</td>\n",
       "      <td>-1.229916</td>\n",
       "      <td>-0.658697</td>\n",
       "      <td>1.293731</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087181</td>\n",
       "      <td>-0.350481</td>\n",
       "      <td>2.074011</td>\n",
       "      <td>-0.419600</td>\n",
       "      <td>-0.479094</td>\n",
       "      <td>-0.214086</td>\n",
       "      <td>-0.287712</td>\n",
       "      <td>-0.112274</td>\n",
       "      <td>-0.16885</td>\n",
       "      <td>-0.048158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.676667</td>\n",
       "      <td>1.149611</td>\n",
       "      <td>-0.130534</td>\n",
       "      <td>-0.243983</td>\n",
       "      <td>-0.915389</td>\n",
       "      <td>-0.30579</td>\n",
       "      <td>-0.563993</td>\n",
       "      <td>-0.891735</td>\n",
       "      <td>1.397518</td>\n",
       "      <td>0.204281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087181</td>\n",
       "      <td>-0.350481</td>\n",
       "      <td>-0.482158</td>\n",
       "      <td>2.383223</td>\n",
       "      <td>-0.479094</td>\n",
       "      <td>-0.214086</td>\n",
       "      <td>-0.287712</td>\n",
       "      <td>-0.112274</td>\n",
       "      <td>-0.16885</td>\n",
       "      <td>-0.048158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.398724</td>\n",
       "      <td>-0.148958</td>\n",
       "      <td>-0.435436</td>\n",
       "      <td>-0.169628</td>\n",
       "      <td>-0.915389</td>\n",
       "      <td>-0.30579</td>\n",
       "      <td>0.340581</td>\n",
       "      <td>-0.130827</td>\n",
       "      <td>-0.658697</td>\n",
       "      <td>-0.544715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087181</td>\n",
       "      <td>-0.350481</td>\n",
       "      <td>-0.482158</td>\n",
       "      <td>-0.419600</td>\n",
       "      <td>2.087275</td>\n",
       "      <td>-0.214086</td>\n",
       "      <td>-0.287712</td>\n",
       "      <td>-0.112274</td>\n",
       "      <td>-0.16885</td>\n",
       "      <td>-0.048158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   No of Bedrooms  No of Bathrooms  Flat Area (in Sqft)  Lot Area (in Sqft)  \\\n",
       "0       -0.398724        -1.447526            -0.979905           -0.228291   \n",
       "1       -0.398724         0.175684             0.533718           -0.189858   \n",
       "2       -1.474115        -1.447526            -1.426369           -0.123276   \n",
       "3        0.676667         1.149611            -0.130534           -0.243983   \n",
       "4       -0.398724        -0.148958            -0.435436           -0.169628   \n",
       "\n",
       "   No of Floors  No of Times Visited  Overall Grade  \\\n",
       "0     -0.915389             -0.30579      -0.563993   \n",
       "1      0.936817             -0.30579      -0.563993   \n",
       "2     -0.915389             -0.30579      -1.468566   \n",
       "3     -0.915389             -0.30579      -0.563993   \n",
       "4     -0.915389             -0.30579       0.340581   \n",
       "\n",
       "   Area of the House from Basement (in Sqft)  Basement Area (in Sqft)  \\\n",
       "0                                  -0.734722                -0.658697   \n",
       "1                                   0.460990                 0.245134   \n",
       "2                                  -1.229916                -0.658697   \n",
       "3                                  -0.891735                 1.397518   \n",
       "4                                  -0.130827                -0.658697   \n",
       "\n",
       "   Age of House (in Years)  ...  Waterfront_View_Yes  \\\n",
       "0                 0.544734  ...            -0.087181   \n",
       "1                 0.680915  ...            -0.087181   \n",
       "2                 1.293731  ...            -0.087181   \n",
       "3                 0.204281  ...            -0.087181   \n",
       "4                -0.544715  ...            -0.087181   \n",
       "\n",
       "   Zipcode_Group_Zipcode_Group_1  Zipcode_Group_Zipcode_Group_2  \\\n",
       "0                      -0.350481                      -0.482158   \n",
       "1                      -0.350481                       2.074011   \n",
       "2                      -0.350481                       2.074011   \n",
       "3                      -0.350481                      -0.482158   \n",
       "4                      -0.350481                      -0.482158   \n",
       "\n",
       "   Zipcode_Group_Zipcode_Group_3  Zipcode_Group_Zipcode_Group_4  \\\n",
       "0                      -0.419600                      -0.479094   \n",
       "1                      -0.419600                      -0.479094   \n",
       "2                      -0.419600                      -0.479094   \n",
       "3                       2.383223                      -0.479094   \n",
       "4                      -0.419600                       2.087275   \n",
       "\n",
       "   Zipcode_Group_Zipcode_Group_5  Zipcode_Group_Zipcode_Group_6  \\\n",
       "0                      -0.214086                      -0.287712   \n",
       "1                      -0.214086                      -0.287712   \n",
       "2                      -0.214086                      -0.287712   \n",
       "3                      -0.214086                      -0.287712   \n",
       "4                      -0.214086                      -0.287712   \n",
       "\n",
       "   Zipcode_Group_Zipcode_Group_7  Zipcode_Group_Zipcode_Group_8  \\\n",
       "0                      -0.112274                       -0.16885   \n",
       "1                      -0.112274                       -0.16885   \n",
       "2                      -0.112274                       -0.16885   \n",
       "3                      -0.112274                       -0.16885   \n",
       "4                      -0.112274                       -0.16885   \n",
       "\n",
       "   Zipcode_Group_Zipcode_Group_9  \n",
       "0                      -0.048158  \n",
       "1                      -0.048158  \n",
       "2                      -0.048158  \n",
       "3                      -0.048158  \n",
       "4                      -0.048158  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "Y = data['Sale_Price']\n",
    "X = scaler.fit_transform(data.drop(columns=['Sale_Price']))\n",
    "X = pd.DataFrame(data = X,columns = data.drop(columns = ['Sale_Price']).columns)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6706ee1",
   "metadata": {},
   "source": [
    "# Train/Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02a6acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['Sale_Price']\n",
    "X = data.drop(columns = ['Sale_Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "faea3556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15126, 30), (6483, 30), (15126,), (6483,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.3,random_state = 101)\n",
    "\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2245aa4",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5d0ede8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(normalize=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(normalize = True)\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "140f4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "112afde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.846235554246878"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a5edd6",
   "metadata": {},
   "source": [
    "#  Forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d3581a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_r2(data_x,data_y,predictions):\n",
    "    from sklearn.metrics import r2_score\n",
    "    R = r2_score(data_y,predictions)\n",
    "    n = len(data_y)\n",
    "    m = len(data_x.columns)\n",
    "    adj_R = 1 -((1-R)*(n-1))/(n-m-1)\n",
    "    return adj_R   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "749ff484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8455205924718325"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2(x_test,y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d89ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_r2(X,Y,model):\n",
    "    model.fit(X,Y)\n",
    "    pred = model.predict(X)\n",
    "    m = len(X.columns)\n",
    "    r2 = adj_r2(m,Y,pred)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e28e781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(model ,X ,Y,max_features):\n",
    "    '''\n",
    "    X=independent variable\n",
    "    Y=dependent variable\n",
    "    model = predictive model\n",
    "    max_features = selects best features upto max feature value\n",
    "    \n",
    "    Returns:\n",
    "    Rmax:adjusted r2 of the final model\n",
    "    history:list of Rmax at every new independent variable added to the model\n",
    "    x[f_col]:best features upto max_features\n",
    "    '''\n",
    "    \n",
    "    f_col = []\n",
    "    history = []\n",
    "    \n",
    "    for i in range(max_features):\n",
    "        \n",
    "        f_col.append('blank')\n",
    "        tem = f_col[:]\n",
    "        Rmax = -1\n",
    "        \n",
    "        for var in X.columns:\n",
    "          tem[-1] = var\n",
    "          r2 = return_r2(X[tem], X, model)\n",
    "          if r2>=Rmax:\n",
    "              Rmax = r2\n",
    "              f_col[-1] = var\n",
    "              elim = var\n",
    "                \n",
    "        print(\"Selected\",f_col[-1],\"with new r2 =\",Rmax)\n",
    "        history.append(Rmax)\n",
    "    \n",
    "    return Rmax,history,X[f_col]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acb8590e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12596\\2929699936.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msel_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_selection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12596\\974697434.py\u001b[0m in \u001b[0;36mforward_selection\u001b[1;34m(model, X, Y, max_features)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m           \u001b[0mtem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m           \u001b[0mr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_r2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[0mRmax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m               \u001b[0mRmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12596\\3223732353.py\u001b[0m in \u001b[0;36mreturn_r2\u001b[1;34m(X, Y, model)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madj_r2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12596\\2032301161.py\u001b[0m in \u001b[0;36madj_r2\u001b[1;34m(data_x, data_y, predictions)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0madj_R\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0madj_R\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(normalize = True)\n",
    "\n",
    "score, history, sel_data = forward_selection(lr, x_train, y_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1139434f",
   "metadata": {},
   "source": [
    "# Backward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c88fbd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(model,X,Y,min_features):\n",
    "    \n",
    "    elim_data = X[:]\n",
    "    r2_history = []\n",
    "    base_r2 = return_r2(elim_data,Y,model)\n",
    "    print(\"base r2 is\",base_r2)\n",
    "    \n",
    "    \n",
    "    for i in range(X.shape[1] - min_features):\n",
    "        \n",
    "        difference = -100\n",
    "        \n",
    "        for var in elim_data.columns:\n",
    "            tem = elim_data.drop(columns = [var])\n",
    "            r2 = return_r2(tem, Y,model)\n",
    "            \n",
    "            if(r2 - base_r2) > difference:\n",
    "                difference = r2 -base_r2\n",
    "                eliminate = var\n",
    "                new_r2 = r2\n",
    "                \n",
    "        elim_data.drop(columns = [eliminate], inplace = True)\n",
    "        r2_history.append(new_r2)\n",
    "        print(eliminate,\"Eliminated : new adj_r2 = \",new_r2,)\n",
    "        base_r2 = new_r2\n",
    "    \n",
    "    return base_r2,r2_history, elim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e8cf8ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12596\\1894709139.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msurvived_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackward_elimination\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12596\\1245601779.py\u001b[0m in \u001b[0;36mbackward_elimination\u001b[1;34m(model, X, Y, min_features)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0melim_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mr2_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mbase_r2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_r2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melim_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"base r2 is\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbase_r2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12596\\3223732353.py\u001b[0m in \u001b[0;36mreturn_r2\u001b[1;34m(X, Y, model)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madj_r2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12596\\2032301161.py\u001b[0m in \u001b[0;36madj_r2\u001b[1;34m(data_x, data_y, predictions)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0madj_R\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0madj_R\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(normalize = True)\n",
    "\n",
    "score,history,survived_data = backward_elimination(lr,x_train,y_train,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3464269e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "plt.style.use(['seaborn-dark-palette','dark_background'])\n",
      "import warnings\n",
      "warnings.filterwarnings(action = 'ignore')\n",
      "data = pd.read_csv('Transformed_Housing_Data2.csv')\n",
      "data.head()\n",
      "#scaling the dataset\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "scaler = StandardScaler()\n",
      "Y = data['Sale_Price']\n",
      "X = scaler.fit_transform(data.drop(columns=['Sale_Price']))\n",
      "X = pd.DataFrame(data = X,columns = data.drop(columns = ['Sale_Price']).columns)\n",
      "X.head()\n",
      "Y = data['Sale_Price']\n",
      "X = data.drop(columns = ['Sale_Price'])\n",
      "from sklearn.model_selection import train_test_split\n",
      "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.3,random_state = 101)\n",
      "\n",
      "x_train.shape,x_test.shape,y_train.shape,y_test.shape\n",
      "from sklearn.linear_model import LinearRegression\n",
      "lr = LinearRegression(normalize = True)\n",
      "lr.fit(x_train,y_train)\n",
      "predictions = lr.predict(x_test)\n",
      "lr.score(x_test,y_test)\n",
      "def adj_r2(data_x,data_y,predictions):\n",
      "    from sklearn.metrics import r2_score\n",
      "    R = r2_score(data_y,predictions)\n",
      "    n = len(data_y)\n",
      "    m = len(data_x.columns)\n",
      "    adj_R = 1 -((1-R)*(n-1))/(n-m-1)\n",
      "    return adj_R\n",
      "adj_r2(x_test,y_test,predictions)\n",
      "def return_r2(X,Y,model):\n",
      "    model.fit(X,Y)\n",
      "    pred = model.predict(X)\n",
      "    m = len(X.columns)\n",
      "    r2 = adj_r2(m,Y,pred)\n",
      "    return r2\n",
      "def feature_selection(model ,X ,Y,max_features):\n",
      "    '''\n",
      "    X=independent variable\n",
      "    Y=dependent variable\n",
      "    model = predictive model\n",
      "    max_features = selects best features upto max feature value\n",
      "    \n",
      "    Returns:\n",
      "    Rmax:adjusted r2 of the final model\n",
      "    history:list of Rmax at every new independent variable added to the model\n",
      "    x[f_col]:best features upto max_features\n",
      "    '''\n",
      "    \n",
      "    f_col = []\n",
      "    history = []\n",
      "    \n",
      "    for i in range(max_features):\n",
      "        f_col.append('blank')\n",
      "        tem = f_col[:]\n",
      "        Rmax = -1\n",
      "        \n",
      "        for var in X.columns:\n",
      "            tem[-1] = var\n",
      "            r2 = return_r2(X[tem], X, model)\n",
      "            if r2>=Rmax:\n",
      "                Rmax = r2\n",
      "                f_col[-1] = var\n",
      "                elim = var\n",
      "                \n",
      "        print(\"Selected\",f_col[-1],\"with new r2 =\",Rmax)\n",
      "        history.append(Rmax)\n",
      "    \n",
      "    return Rmax,history,X[f_col]\n",
      "from sklearn.linear_model import LinearRegression\n",
      "lr = LinearRegression(normalize = True)\n",
      "\n",
      "score,history, sel_data = feature_selection(lr, x_train, y_train, 5)\n",
      "def feature_selection(model ,X ,Y,max_features):\n",
      "    '''\n",
      "    X=independent variable\n",
      "    Y=dependent variable\n",
      "    model = predictive model\n",
      "    max_features = selects best features upto max feature value\n",
      "    \n",
      "    Returns:\n",
      "    Rmax:adjusted r2 of the final model\n",
      "    history:list of Rmax at every new independent variable added to the model\n",
      "    x[f_col]:best features upto max_features\n",
      "    '''\n",
      "    \n",
      "    f_col = []\n",
      "    history = []\n",
      "    \n",
      "    for i in range(max_features):\n",
      "        \n",
      "        f_col.append('blank')\n",
      "        tem = f_col[:]\n",
      "        Rmax = -1\n",
      "        \n",
      "        for var in X.columns:\n",
      "          tem[-1] = var\n",
      "           r2 = return_r2(X[tem], X, model)\n",
      "           if r2>=Rmax:\n",
      "              Rmax = r2\n",
      "              f_col[-1] = var\n",
      "              elim = var\n",
      "                \n",
      "        print(\"Selected\",f_col[-1],\"with new r2 =\",Rmax)\n",
      "        history.append(Rmax)\n",
      "    \n",
      "    return Rmax,history,X[f_col]\n",
      "from sklearn.linear_model import LinearRegression\n",
      "lr = LinearRegression(normalize = True)\n",
      "\n",
      "score,history, sel_data = feature_selection(lr, x_train, y_train, 5)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "lr = LinearRegression(normalize = True)\n",
      "\n",
      "score, history, sel_data = forward_selection(lr, x_train, y_train, 5)\n",
      "def forward_selection(model ,X ,Y,max_features):\n",
      "    '''\n",
      "    X=independent variable\n",
      "    Y=dependent variable\n",
      "    model = predictive model\n",
      "    max_features = selects best features upto max feature value\n",
      "    \n",
      "    Returns:\n",
      "    Rmax:adjusted r2 of the final model\n",
      "    history:list of Rmax at every new independent variable added to the model\n",
      "    x[f_col]:best features upto max_features\n",
      "    '''\n",
      "    \n",
      "    f_col = []\n",
      "    history = []\n",
      "    \n",
      "    for i in range(max_features):\n",
      "        \n",
      "        f_col.append('blank')\n",
      "        tem = f_col[:]\n",
      "        Rmax = -1\n",
      "        \n",
      "        for var in X.columns:\n",
      "          tem[-1] = var\n",
      "           r2 = return_r2(X[tem], X, model)\n",
      "           if r2>=Rmax:\n",
      "              Rmax = r2\n",
      "              f_col[-1] = var\n",
      "              elim = var\n",
      "                \n",
      "        print(\"Selected\",f_col[-1],\"with new r2 =\",Rmax)\n",
      "        history.append(Rmax)\n",
      "    \n",
      "    return Rmax,history,X[f_col]\n",
      "def forward_selection(model ,X ,Y,max_features):\n",
      "    '''\n",
      "    X=independent variable\n",
      "    Y=dependent variable\n",
      "    model = predictive model\n",
      "    max_features = selects best features upto max feature value\n",
      "    \n",
      "    Returns:\n",
      "    Rmax:adjusted r2 of the final model\n",
      "    history:list of Rmax at every new independent variable added to the model\n",
      "    x[f_col]:best features upto max_features\n",
      "    '''\n",
      "    \n",
      "    f_col = []\n",
      "    history = []\n",
      "    \n",
      "    for i in range(max_features):\n",
      "        \n",
      "        f_col.append('blank')\n",
      "        tem = f_col[:]\n",
      "        Rmax = -1\n",
      "        \n",
      "        for var in X.columns:\n",
      "          tem[-1] = var\n",
      "          r2 = return_r2(X[tem], X, model)\n",
      "          if r2>=Rmax:\n",
      "              Rmax = r2\n",
      "              f_col[-1] = var\n",
      "              elim = var\n",
      "                \n",
      "        print(\"Selected\",f_col[-1],\"with new r2 =\",Rmax)\n",
      "        history.append(Rmax)\n",
      "    \n",
      "    return Rmax,history,X[f_col]\n",
      "from sklearn.linear_model import LinearRegression\n",
      "lr = LinearRegression(normalize = True)\n",
      "\n",
      "score, history, sel_data = forward_selection(lr, x_train, y_train, 5)\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "plt.style.use(['seaborn-dark-palette','dark_background'])\n",
      "import warnings\n",
      "warnings.filterwarnings(action = 'ignore')\n",
      "data = pd.read_csv('Transformed_Housing_Data2.csv')\n",
      "data.head()\n",
      "#scaling the dataset\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "scaler = StandardScaler()\n",
      "Y = data['Sale_Price']\n",
      "X = scaler.fit_transform(data.drop(columns=['Sale_Price']))\n",
      "X = pd.DataFrame(data = X,columns = data.drop(columns = ['Sale_Price']).columns)\n",
      "X.head()\n",
      "Y = data['Sale_Price']\n",
      "X = data.drop(columns = ['Sale_Price'])\n",
      "from sklearn.model_selection import train_test_split\n",
      "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.3,random_state = 101)\n",
      "\n",
      "x_train.shape,x_test.shape,y_train.shape,y_test.shape\n",
      "from sklearn.linear_model import LinearRegression\n",
      "lr = LinearRegression(normalize = True)\n",
      "lr.fit(x_train,y_train)\n",
      "predictions = lr.predict(x_test)\n",
      "lr.score(x_test,y_test)\n",
      "def adj_r2(data_x,data_y,predictions):\n",
      "    from sklearn.metrics import r2_score\n",
      "    R = r2_score(data_y,predictions)\n",
      "    n = len(data_y)\n",
      "    m = len(data_x.columns)\n",
      "    adj_R = 1 -((1-R)*(n-1))/(n-m-1)\n",
      "    return adj_R\n",
      "adj_r2(x_test,y_test,predictions)\n",
      "def return_r2(X,Y,model):\n",
      "    model.fit(X,Y)\n",
      "    pred = model.predict(X)\n",
      "    m = len(X.columns)\n",
      "    r2 = adj_r2(m,Y,pred)\n",
      "    return r2\n",
      "def backward_elimination(model,X,Y,min_features):\n",
      "    \n",
      "    elim_data = X[:]\n",
      "    r2_history = []\n",
      "    base_r2 = return_r2(elim_data,Y,model)\n",
      "    print(\"base r2 is\",base_r2)\n",
      "    \n",
      "    \n",
      "    for i in range(X.shape[1] - min_features):\n",
      "        \n",
      "        difference = -100\n",
      "        \n",
      "        for var in elim_data.columns:\n",
      "            tem = elim_data.drop(columns = [var])\n",
      "            r2 = return_r2(tem, Y,model)\n",
      "            \n",
      "            if(r2 - base_r2) > difference:\n",
      "                difference = r2 -base_r2\n",
      "                eliminate = var\n",
      "                new_r2 = r2\n",
      "                \n",
      "       elim_data.drop(columns = [eliminate], inplace = True)\n",
      "       r2_history.append(new_r2)\n",
      "       print(eliminate,\"Eliminated : new adj_r2 = \",new_r2,)\n",
      "       base_r2 = new_r2\n",
      "    \n",
      "   return base_r2,r2_history, elim_data\n",
      "def backward_elimination(model,X,Y,min_features):\n",
      "    \n",
      "    elim_data = X[:]\n",
      "    r2_history = []\n",
      "    base_r2 = return_r2(elim_data,Y,model)\n",
      "    print(\"base r2 is\",base_r2)\n",
      "    \n",
      "    \n",
      "    for i in range(X.shape[1] - min_features):\n",
      "        \n",
      "        difference = -100\n",
      "        \n",
      "        for var in elim_data.columns:\n",
      "            tem = elim_data.drop(columns = [var])\n",
      "            r2 = return_r2(tem, Y,model)\n",
      "            \n",
      "            if(r2 - base_r2) > difference:\n",
      "                difference = r2 -base_r2\n",
      "                eliminate = var\n",
      "                new_r2 = r2\n",
      "                \n",
      "        elim_data.drop(columns = [eliminate], inplace = True)\n",
      "        r2_history.append(new_r2)\n",
      "        print(eliminate,\"Eliminated : new adj_r2 = \",new_r2,)\n",
      "        base_r2 = new_r2\n",
      "    \n",
      "   return base_r2,r2_history, elim_data\n",
      "def backward_elimination(model,X,Y,min_features):\n",
      "    \n",
      "    elim_data = X[:]\n",
      "    r2_history = []\n",
      "    base_r2 = return_r2(elim_data,Y,model)\n",
      "    print(\"base r2 is\",base_r2)\n",
      "    \n",
      "    \n",
      "    for i in range(X.shape[1] - min_features):\n",
      "        \n",
      "        difference = -100\n",
      "        \n",
      "        for var in elim_data.columns:\n",
      "            tem = elim_data.drop(columns = [var])\n",
      "            r2 = return_r2(tem, Y,model)\n",
      "            \n",
      "            if(r2 - base_r2) > difference:\n",
      "                difference = r2 -base_r2\n",
      "                eliminate = var\n",
      "                new_r2 = r2\n",
      "                \n",
      "        elim_data.drop(columns = [eliminate], inplace = True)\n",
      "        r2_history.append(new_r2)\n",
      "        print(eliminate,\"Eliminated : new adj_r2 = \",new_r2,)\n",
      "        base_r2 = new_r2\n",
      "    \n",
      "    return base_r2,r2_history, elim_data\n",
      "from sklearn.linear_model import LinearRegression\n",
      "lr = LinearRegression(normalize = True)\n",
      "\n",
      "score,history,survived_data = backward_elimination(lr,x_train,y_train,1)\n",
      "history\n"
     ]
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5582ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5), dpi = 150)\n",
    "plt.plot()\n",
    "plt.xlabel()\n",
    "plt.ylabel()\n",
    "plt.title()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
